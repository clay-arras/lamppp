# ----------------------------------------
# PyTorch/Caffe2 Operator Micro-benchmarks
# ----------------------------------------
# Tag : short

# Benchmarking PyTorch: exp
# Mode: Eager
# Name: exp_M128_N128
# Input: M: 128, N: 128
Forward Execution Time (us) : 3.705

# Benchmarking PyTorch: exp
# Mode: Eager
# Name: exp_M256_N256
# Input: M: 256, N: 256
Forward Execution Time (us) : 3.750

# Benchmarking PyTorch: exp
# Mode: Eager
# Name: exp_M1024_N1024
# Input: M: 1024, N: 1024
Forward Execution Time (us) : 6.295

# Benchmarking PyTorch: log
# Mode: Eager
# Name: log_M128_N128
# Input: M: 128, N: 128
Forward Execution Time (us) : 3.677

# Benchmarking PyTorch: log
# Mode: Eager
# Name: log_M256_N256
# Input: M: 256, N: 256
Forward Execution Time (us) : 3.587

# Benchmarking PyTorch: log
# Mode: Eager
# Name: log_M1024_N1024
# Input: M: 1024, N: 1024
Forward Execution Time (us) : 7.116

# Benchmarking PyTorch: sin
# Mode: Eager
# Name: sin_M128_N128
# Input: M: 128, N: 128
Forward Execution Time (us) : 3.634

# Benchmarking PyTorch: sin
# Mode: Eager
# Name: sin_M256_N256
# Input: M: 256, N: 256
Forward Execution Time (us) : 3.851

# Benchmarking PyTorch: sin
# Mode: Eager
# Name: sin_M1024_N1024
# Input: M: 1024, N: 1024
Forward Execution Time (us) : 6.969

# Benchmarking PyTorch: cos
# Mode: Eager
# Name: cos_M128_N128
# Input: M: 128, N: 128
Forward Execution Time (us) : 3.690

# Benchmarking PyTorch: cos
# Mode: Eager
# Name: cos_M256_N256
# Input: M: 256, N: 256
Forward Execution Time (us) : 3.546

# Benchmarking PyTorch: cos
# Mode: Eager
# Name: cos_M1024_N1024
# Input: M: 1024, N: 1024
Forward Execution Time (us) : 7.009

# Benchmarking PyTorch: abs
# Mode: Eager
# Name: abs_M128_N128
# Input: M: 128, N: 128
Forward Execution Time (us) : 4.284

# Benchmarking PyTorch: abs
# Mode: Eager
# Name: abs_M256_N256
# Input: M: 256, N: 256
Forward Execution Time (us) : 4.328

# Benchmarking PyTorch: abs
# Mode: Eager
# Name: abs_M1024_N1024
# Input: M: 1024, N: 1024
Forward Execution Time (us) : 6.178

# Benchmarking PyTorch: add
# Mode: Eager
# Name: add_M128_N128
# Input: M: 128, N: 128
Forward Execution Time (us) : 3.625

# Benchmarking PyTorch: add
# Mode: Eager
# Name: add_M256_N256
# Input: M: 256, N: 256
Forward Execution Time (us) : 3.644

# Benchmarking PyTorch: add
# Mode: Eager
# Name: add_M1024_N1024
# Input: M: 1024, N: 1024
Forward Execution Time (us) : 7.011

# Benchmarking PyTorch: sub
# Mode: Eager
# Name: sub_M128_N128
# Input: M: 128, N: 128
Forward Execution Time (us) : 3.955

# Benchmarking PyTorch: sub
# Mode: Eager
# Name: sub_M256_N256
# Input: M: 256, N: 256
Forward Execution Time (us) : 3.791

# Benchmarking PyTorch: sub
# Mode: Eager
# Name: sub_M1024_N1024
# Input: M: 1024, N: 1024
Forward Execution Time (us) : 6.948

# Benchmarking PyTorch: mul
# Mode: Eager
# Name: mul_M128_N128
# Input: M: 128, N: 128
Forward Execution Time (us) : 3.627

# Benchmarking PyTorch: mul
# Mode: Eager
# Name: mul_M256_N256
# Input: M: 256, N: 256
Forward Execution Time (us) : 3.726

# Benchmarking PyTorch: mul
# Mode: Eager
# Name: mul_M1024_N1024
# Input: M: 1024, N: 1024
Forward Execution Time (us) : 6.931

# Benchmarking PyTorch: div
# Mode: Eager
# Name: div_M128_N128
# Input: M: 128, N: 128
Forward Execution Time (us) : 5.438

# Benchmarking PyTorch: div
# Mode: Eager
# Name: div_M256_N256
# Input: M: 256, N: 256
Forward Execution Time (us) : 4.030

# Benchmarking PyTorch: div
# Mode: Eager
# Name: div_M1024_N1024
# Input: M: 1024, N: 1024
Forward Execution Time (us) : 7.050

# ----------------------------------------
# PyTorch/Caffe2 Operator Micro-benchmarks
# ----------------------------------------
# Tag : short

# Benchmarking PyTorch: add
# Mode: Eager
# Name: add_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32
# Input: in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32
Forward Execution Time (us) : 301.468

# Benchmarking PyTorch: sub
# Mode: Eager
# Name: sub_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32
# Input: in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32
Forward Execution Time (us) : 175.305

# Benchmarking PyTorch: div
# Mode: Eager
# Name: div_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32
# Input: in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32
Forward Execution Time (us) : 40.031

# Benchmarking PyTorch: mul
# Mode: Eager
# Name: mul_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32
# Input: in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32
Forward Execution Time (us) : 117.819

# Benchmarking PyTorch: add
# Mode: Eager
# Name: add_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 1.454

# Benchmarking PyTorch: add
# Mode: Eager
# Name: add_M1_N1_K1_cuda_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 1, N: 1, K: 1, device: cuda, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 3.709

# Benchmarking PyTorch: add
# Mode: Eager
# Name: add_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 27.105

# Benchmarking PyTorch: add
# Mode: Eager
# Name: add_M64_N64_K64_cuda_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 64, device: cuda, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 4.299

# Benchmarking PyTorch: add
# Mode: Eager
# Name: add_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 157.518

# Benchmarking PyTorch: add
# Mode: Eager
# Name: add_M64_N64_K128_cuda_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 128, device: cuda, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 4.587

# Benchmarking PyTorch: sub
# Mode: Eager
# Name: sub_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 1.409

# Benchmarking PyTorch: sub
# Mode: Eager
# Name: sub_M1_N1_K1_cuda_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 1, N: 1, K: 1, device: cuda, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 4.011

# Benchmarking PyTorch: sub
# Mode: Eager
# Name: sub_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 20.934

# Benchmarking PyTorch: sub
# Mode: Eager
# Name: sub_M64_N64_K64_cuda_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 64, device: cuda, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 3.915

# Benchmarking PyTorch: sub
# Mode: Eager
# Name: sub_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 20.056

# Benchmarking PyTorch: sub
# Mode: Eager
# Name: sub_M64_N64_K128_cuda_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 128, device: cuda, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 4.529

# Benchmarking PyTorch: div
# Mode: Eager
# Name: div_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 3.270

# Benchmarking PyTorch: div
# Mode: Eager
# Name: div_M1_N1_K1_cuda_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 1, N: 1, K: 1, device: cuda, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 3.919

# Benchmarking PyTorch: div
# Mode: Eager
# Name: div_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 52.932

# Benchmarking PyTorch: div
# Mode: Eager
# Name: div_M64_N64_K64_cuda_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 64, device: cuda, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 8.147

# Benchmarking PyTorch: div
# Mode: Eager
# Name: div_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 66.476

# Benchmarking PyTorch: div
# Mode: Eager
# Name: div_M64_N64_K128_cuda_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 128, device: cuda, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 14.429

# Benchmarking PyTorch: mul
# Mode: Eager
# Name: mul_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 1.721

# Benchmarking PyTorch: mul
# Mode: Eager
# Name: mul_M1_N1_K1_cuda_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 1, N: 1, K: 1, device: cuda, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 4.063

# Benchmarking PyTorch: mul
# Mode: Eager
# Name: mul_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 17.352

# Benchmarking PyTorch: mul
# Mode: Eager
# Name: mul_M64_N64_K64_cuda_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 64, device: cuda, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 4.429

# Benchmarking PyTorch: mul
# Mode: Eager
# Name: mul_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 23.882

# Benchmarking PyTorch: mul
# Mode: Eager
# Name: mul_M64_N64_K128_cuda_dtype_onetorch.int32_dtype_twotorch.int32
# Input: M: 64, N: 64, K: 128, device: cuda, dtype_one: torch.int32, dtype_two: torch.int32
Forward Execution Time (us) : 4.346

# ----------------------------------------
# PyTorch/Caffe2 Operator Micro-benchmarks
# ----------------------------------------
# Tag : short

# Benchmarking PyTorch: abs
# Mode: Eager
# Name: abs_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 109.247

# Benchmarking PyTorch: abs
# Mode: Eager
# Name: abs_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.478

# Benchmarking PyTorch: abs_
# Mode: Eager
# Name: abs__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 14.973

# Benchmarking PyTorch: abs_
# Mode: Eager
# Name: abs__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 2.929

# Benchmarking PyTorch: clamp
# Mode: Eager
# Name: clamp_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 13.477

# Benchmarking PyTorch: clamp
# Mode: Eager
# Name: clamp_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 5.489

# Benchmarking PyTorch: clone
# Mode: Eager
# Name: clone_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 13.479

# Benchmarking PyTorch: clone
# Mode: Eager
# Name: clone_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 5.352

# Benchmarking PyTorch: cos
# Mode: Eager
# Name: cos_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 28.413

# Benchmarking PyTorch: cos
# Mode: Eager
# Name: cos_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.043

# Benchmarking PyTorch: cos_
# Mode: Eager
# Name: cos__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 27.526

# Benchmarking PyTorch: cos_
# Mode: Eager
# Name: cos__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 2.979

# Benchmarking PyTorch: exp
# Mode: Eager
# Name: exp_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 47.256

# Benchmarking PyTorch: exp
# Mode: Eager
# Name: exp_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 5.123

# Benchmarking PyTorch: exp_
# Mode: Eager
# Name: exp__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 72.591

# Benchmarking PyTorch: exp_
# Mode: Eager
# Name: exp__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.781

# Benchmarking PyTorch: expm1
# Mode: Eager
# Name: expm1_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 125.643

# Benchmarking PyTorch: expm1
# Mode: Eager
# Name: expm1_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 5.044

# Benchmarking PyTorch: expm1_
# Mode: Eager
# Name: expm1__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 158.439

# Benchmarking PyTorch: expm1_
# Mode: Eager
# Name: expm1__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.963

# Benchmarking PyTorch: floor
# Mode: Eager
# Name: floor_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 15.852

# Benchmarking PyTorch: floor
# Mode: Eager
# Name: floor_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.679

# Benchmarking PyTorch: floor_
# Mode: Eager
# Name: floor__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 13.829

# Benchmarking PyTorch: floor_
# Mode: Eager
# Name: floor__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.899

# Benchmarking PyTorch: frac
# Mode: Eager
# Name: frac_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 16.932

# Benchmarking PyTorch: frac
# Mode: Eager
# Name: frac_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 5.002

# Benchmarking PyTorch: frac_
# Mode: Eager
# Name: frac__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 13.849

# Benchmarking PyTorch: frac_
# Mode: Eager
# Name: frac__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.192

# Benchmarking PyTorch: gelu
# Mode: Eager
# Name: gelu_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 43.013

# Benchmarking PyTorch: gelu
# Mode: Eager
# Name: gelu_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.296

# Benchmarking PyTorch: hardshrink
# Mode: Eager
# Name: hardshrink_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 21.327

# Benchmarking PyTorch: hardshrink
# Mode: Eager
# Name: hardshrink_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.561

# Benchmarking PyTorch: lgamma
# Mode: Eager
# Name: lgamma_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 461.178

# Benchmarking PyTorch: lgamma
# Mode: Eager
# Name: lgamma_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.409

# Benchmarking PyTorch: log
# Mode: Eager
# Name: log_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 21.382

# Benchmarking PyTorch: log
# Mode: Eager
# Name: log_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.245

# Benchmarking PyTorch: log10
# Mode: Eager
# Name: log10_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 28.848

# Benchmarking PyTorch: log10
# Mode: Eager
# Name: log10_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.105

# Benchmarking PyTorch: log10_
# Mode: Eager
# Name: log10__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 78.275

# Benchmarking PyTorch: log10_
# Mode: Eager
# Name: log10__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.172

# Benchmarking PyTorch: log1p
# Mode: Eager
# Name: log1p_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 62.527

# Benchmarking PyTorch: log1p
# Mode: Eager
# Name: log1p_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.314

# Benchmarking PyTorch: log1p_
# Mode: Eager
# Name: log1p__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 67.864

# Benchmarking PyTorch: log1p_
# Mode: Eager
# Name: log1p__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.679

# Benchmarking PyTorch: log2
# Mode: Eager
# Name: log2_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 32.851

# Benchmarking PyTorch: log2
# Mode: Eager
# Name: log2_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.227

# Benchmarking PyTorch: log2_
# Mode: Eager
# Name: log2__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 98.914

# Benchmarking PyTorch: log2_
# Mode: Eager
# Name: log2__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.209

# Benchmarking PyTorch: log_
# Mode: Eager
# Name: log__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 94.543

# Benchmarking PyTorch: log_
# Mode: Eager
# Name: log__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.964

# Benchmarking PyTorch: logit
# Mode: Eager
# Name: logit_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 35.902

# Benchmarking PyTorch: logit
# Mode: Eager
# Name: logit_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 5.440

# Benchmarking PyTorch: logit_
# Mode: Eager
# Name: logit__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 106.327

# Benchmarking PyTorch: logit_
# Mode: Eager
# Name: logit__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.788

# Benchmarking PyTorch: neg
# Mode: Eager
# Name: neg_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 19.150

# Benchmarking PyTorch: neg
# Mode: Eager
# Name: neg_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.713

# Benchmarking PyTorch: neg_
# Mode: Eager
# Name: neg__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 16.942

# Benchmarking PyTorch: neg_
# Mode: Eager
# Name: neg__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.440

# Benchmarking PyTorch: reciprocal
# Mode: Eager
# Name: reciprocal_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 36.181

# Benchmarking PyTorch: reciprocal
# Mode: Eager
# Name: reciprocal_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.386

# Benchmarking PyTorch: reciprocal_
# Mode: Eager
# Name: reciprocal__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 37.387

# Benchmarking PyTorch: reciprocal_
# Mode: Eager
# Name: reciprocal__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.350

# Benchmarking PyTorch: relu
# Mode: Eager
# Name: relu_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 13.876

# Benchmarking PyTorch: relu
# Mode: Eager
# Name: relu_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 5.045

# Benchmarking PyTorch: relu_
# Mode: Eager
# Name: relu__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 4638.413

# Benchmarking PyTorch: relu_
# Mode: Eager
# Name: relu__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 13.277

# Benchmarking PyTorch: round
# Mode: Eager
# Name: round_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 11057.820

# Benchmarking PyTorch: round
# Mode: Eager
# Name: round_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 14.496

# Benchmarking PyTorch: round_
# Mode: Eager
# Name: round__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 5436.186

# Benchmarking PyTorch: round_
# Mode: Eager
# Name: round__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 5.596

# Benchmarking PyTorch: rsqrt
# Mode: Eager
# Name: rsqrt_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 10758.363

# Benchmarking PyTorch: rsqrt
# Mode: Eager
# Name: rsqrt_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 5.877

# Benchmarking PyTorch: rsqrt_
# Mode: Eager
# Name: rsqrt__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 10827.637

# Benchmarking PyTorch: rsqrt_
# Mode: Eager
# Name: rsqrt__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 5.752

# Benchmarking PyTorch: sigmoid
# Mode: Eager
# Name: sigmoid_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 8828.639

# Benchmarking PyTorch: sigmoid
# Mode: Eager
# Name: sigmoid_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 17.863

# Benchmarking PyTorch: sigmoid_
# Mode: Eager
# Name: sigmoid__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 80.537

# Benchmarking PyTorch: sigmoid_
# Mode: Eager
# Name: sigmoid__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.311

# Benchmarking PyTorch: sign
# Mode: Eager
# Name: sign_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 21.658

# Benchmarking PyTorch: sign
# Mode: Eager
# Name: sign_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.571

# Benchmarking PyTorch: sgn
# Mode: Eager
# Name: sgn_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 22.021

# Benchmarking PyTorch: sgn
# Mode: Eager
# Name: sgn_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.466

# Benchmarking PyTorch: sin
# Mode: Eager
# Name: sin_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 29.449

# Benchmarking PyTorch: sin
# Mode: Eager
# Name: sin_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.366

# Benchmarking PyTorch: sin_
# Mode: Eager
# Name: sin__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 28.435

# Benchmarking PyTorch: sin_
# Mode: Eager
# Name: sin__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.299

# Benchmarking PyTorch: sinh
# Mode: Eager
# Name: sinh_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 231.257

# Benchmarking PyTorch: sinh
# Mode: Eager
# Name: sinh_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.378

# Benchmarking PyTorch: sqrt
# Mode: Eager
# Name: sqrt_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 13.658

# Benchmarking PyTorch: sqrt
# Mode: Eager
# Name: sqrt_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.478

# Benchmarking PyTorch: sqrt_
# Mode: Eager
# Name: sqrt__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 13.413

# Benchmarking PyTorch: sqrt_
# Mode: Eager
# Name: sqrt__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.017

# Benchmarking PyTorch: square
# Mode: Eager
# Name: square_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 13.961

# Benchmarking PyTorch: square
# Mode: Eager
# Name: square_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 5.087

# Benchmarking PyTorch: square_
# Mode: Eager
# Name: square__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 9.342

# Benchmarking PyTorch: square_
# Mode: Eager
# Name: square__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.990

# Benchmarking PyTorch: tan
# Mode: Eager
# Name: tan_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 50.062

# Benchmarking PyTorch: tan
# Mode: Eager
# Name: tan_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.378

# Benchmarking PyTorch: tan_
# Mode: Eager
# Name: tan__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 48.095

# Benchmarking PyTorch: tan_
# Mode: Eager
# Name: tan__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.328

# Benchmarking PyTorch: tanh
# Mode: Eager
# Name: tanh_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 63.052

# Benchmarking PyTorch: tanh
# Mode: Eager
# Name: tanh_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.685

# Benchmarking PyTorch: tanh_
# Mode: Eager
# Name: tanh__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 55.849

# Benchmarking PyTorch: tanh_
# Mode: Eager
# Name: tanh__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.304

# Benchmarking PyTorch: trunc
# Mode: Eager
# Name: trunc_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 12.963

# Benchmarking PyTorch: trunc
# Mode: Eager
# Name: trunc_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.826

# Benchmarking PyTorch: trunc_
# Mode: Eager
# Name: trunc__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 11.859

# Benchmarking PyTorch: trunc_
# Mode: Eager
# Name: trunc__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.518

# Benchmarking PyTorch: unique
# Mode: Eager
# Name: unique_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 21926.879

# Benchmarking PyTorch: unique
# Mode: Eager
# Name: unique_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 77.864

# Benchmarking PyTorch: zero_
# Mode: Eager
# Name: zero__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 14.649

# Benchmarking PyTorch: zero_
# Mode: Eager
# Name: zero__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.578

# Benchmarking PyTorch: bernoulli_
# Mode: Eager
# Name: bernoulli__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 35.895

# Benchmarking PyTorch: bernoulli_
# Mode: Eager
# Name: bernoulli__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.151

# Benchmarking PyTorch: cauchy_
# Mode: Eager
# Name: cauchy__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 6735.963

# Benchmarking PyTorch: cauchy_
# Mode: Eager
# Name: cauchy__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.809

# Benchmarking PyTorch: digamma_
# Mode: Eager
# Name: digamma__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 1812.934

# Benchmarking PyTorch: digamma_
# Mode: Eager
# Name: digamma__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 124.708

# Benchmarking PyTorch: exponential_
# Mode: Eager
# Name: exponential__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 48.170

# Benchmarking PyTorch: exponential_
# Mode: Eager
# Name: exponential__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.688

# Benchmarking PyTorch: normal_
# Mode: Eager
# Name: normal__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 891.688

# Benchmarking PyTorch: normal_
# Mode: Eager
# Name: normal__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 5.444

# Benchmarking PyTorch: random_
# Mode: Eager
# Name: random__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 867.938

# Benchmarking PyTorch: random_
# Mode: Eager
# Name: random__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.202

# Benchmarking PyTorch: sign_
# Mode: Eager
# Name: sign__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 16.789

# Benchmarking PyTorch: sign_
# Mode: Eager
# Name: sign__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 3.079

# Benchmarking PyTorch: uniform_
# Mode: Eager
# Name: uniform__M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 858.995

# Benchmarking PyTorch: uniform_
# Mode: Eager
# Name: uniform__M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 4.444

# Benchmarking PyTorch: half
# Mode: Eager
# Name: half_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 12.191

# Benchmarking PyTorch: half
# Mode: Eager
# Name: half_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 5.062

# Benchmarking PyTorch: long
# Mode: Eager
# Name: long_M512_N512_cpu
# Input: M: 512, N: 512, device: cpu
Forward Execution Time (us) : 31.230

# Benchmarking PyTorch: long
# Mode: Eager
# Name: long_M512_N512_cuda
# Input: M: 512, N: 512, device: cuda
Forward Execution Time (us) : 6.205

# ----------------------------------------
# PyTorch/Caffe2 Operator Micro-benchmarks
# ----------------------------------------
# Tag : short

# Benchmarking PyTorch: matmul
# Mode: Eager
# Name: matmul_M1_N1_K1_trans_aTrue_trans_bFalse_cpu
# Input: M: 1, N: 1, K: 1, trans_a: True, trans_b: False, device: cpu
Forward Execution Time (us) : 1.602

# Benchmarking PyTorch: matmul
# Mode: Eager
# Name: matmul_M1_N1_K1_trans_aTrue_trans_bFalse_cuda
# Input: M: 1, N: 1, K: 1, trans_a: True, trans_b: False, device: cuda
Forward Execution Time (us) : 5.918

# Benchmarking PyTorch: matmul
# Mode: Eager
# Name: matmul_M128_N128_K128_trans_aTrue_trans_bFalse_cpu
# Input: M: 128, N: 128, K: 128, trans_a: True, trans_b: False, device: cpu
Forward Execution Time (us) : 18.409

# Benchmarking PyTorch: matmul
# Mode: Eager
# Name: matmul_M128_N128_K128_trans_aTrue_trans_bFalse_cuda
# Input: M: 128, N: 128, K: 128, trans_a: True, trans_b: False, device: cuda
Forward Execution Time (us) : 6.542

# Benchmarking PyTorch: matmul
# Mode: Eager
# Name: matmul_M256_N256_K256_trans_aFalse_trans_bTrue_cpu
# Input: M: 256, N: 256, K: 256, trans_a: False, trans_b: True, device: cpu
Forward Execution Time (us) : 76.888

# Benchmarking PyTorch: matmul
# Mode: Eager
# Name: matmul_M256_N256_K256_trans_aFalse_trans_bTrue_cuda
# Input: M: 256, N: 256, K: 256, trans_a: False, trans_b: True, device: cuda
Forward Execution Time (us) : 10.183

# ----------------------------------------
# PyTorch/Caffe2 Operator Micro-benchmarks
# ----------------------------------------
# Tag : short

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V32_dim0_contiguousTrue_cpu
# Input: R: 64, V: 32, dim: 0, contiguous: True, device: cpu
Forward Execution Time (us) : 2.406

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V32_dim0_contiguousTrue_cuda
# Input: R: 64, V: 32, dim: 0, contiguous: True, device: cuda
Forward Execution Time (us) : 5.126

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V32_dim0_contiguousFalse_cpu
# Input: R: 64, V: 32, dim: 0, contiguous: False, device: cpu
Forward Execution Time (us) : 3.149

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V32_dim0_contiguousFalse_cuda
# Input: R: 64, V: 32, dim: 0, contiguous: False, device: cuda
Forward Execution Time (us) : 5.379

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V32_dim1_contiguousTrue_cpu
# Input: R: 64, V: 32, dim: 1, contiguous: True, device: cpu
Forward Execution Time (us) : 2.682

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V32_dim1_contiguousTrue_cuda
# Input: R: 64, V: 32, dim: 1, contiguous: True, device: cuda
Forward Execution Time (us) : 5.173

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V32_dim1_contiguousFalse_cpu
# Input: R: 64, V: 32, dim: 1, contiguous: False, device: cpu
Forward Execution Time (us) : 3.073

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V32_dim1_contiguousFalse_cuda
# Input: R: 64, V: 32, dim: 1, contiguous: False, device: cuda
Forward Execution Time (us) : 5.365

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V512_dim0_contiguousTrue_cpu
# Input: R: 64, V: 512, dim: 0, contiguous: True, device: cpu
Forward Execution Time (us) : 13.296

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V512_dim0_contiguousTrue_cuda
# Input: R: 64, V: 512, dim: 0, contiguous: True, device: cuda
Forward Execution Time (us) : 5.285

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V512_dim0_contiguousFalse_cpu
# Input: R: 64, V: 512, dim: 0, contiguous: False, device: cpu
Forward Execution Time (us) : 10.438

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V512_dim0_contiguousFalse_cuda
# Input: R: 64, V: 512, dim: 0, contiguous: False, device: cuda
Forward Execution Time (us) : 6.015

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V512_dim1_contiguousTrue_cpu
# Input: R: 64, V: 512, dim: 1, contiguous: True, device: cpu
Forward Execution Time (us) : 7.974

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V512_dim1_contiguousTrue_cuda
# Input: R: 64, V: 512, dim: 1, contiguous: True, device: cuda
Forward Execution Time (us) : 5.922

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V512_dim1_contiguousFalse_cpu
# Input: R: 64, V: 512, dim: 1, contiguous: False, device: cpu
Forward Execution Time (us) : 8.429

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R64_V512_dim1_contiguousFalse_cuda
# Input: R: 64, V: 512, dim: 1, contiguous: False, device: cuda
Forward Execution Time (us) : 6.129

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V32_dim0_contiguousTrue_cpu
# Input: R: 256, V: 32, dim: 0, contiguous: True, device: cpu
Forward Execution Time (us) : 2.590

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V32_dim0_contiguousTrue_cuda
# Input: R: 256, V: 32, dim: 0, contiguous: True, device: cuda
Forward Execution Time (us) : 5.134

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V32_dim0_contiguousFalse_cpu
# Input: R: 256, V: 32, dim: 0, contiguous: False, device: cpu
Forward Execution Time (us) : 4.194

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V32_dim0_contiguousFalse_cuda
# Input: R: 256, V: 32, dim: 0, contiguous: False, device: cuda
Forward Execution Time (us) : 5.175

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V32_dim1_contiguousTrue_cpu
# Input: R: 256, V: 32, dim: 1, contiguous: True, device: cpu
Forward Execution Time (us) : 2.790

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V32_dim1_contiguousTrue_cuda
# Input: R: 256, V: 32, dim: 1, contiguous: True, device: cuda
Forward Execution Time (us) : 5.447

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V32_dim1_contiguousFalse_cpu
# Input: R: 256, V: 32, dim: 1, contiguous: False, device: cpu
Forward Execution Time (us) : 4.227

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V32_dim1_contiguousFalse_cuda
# Input: R: 256, V: 32, dim: 1, contiguous: False, device: cuda
Forward Execution Time (us) : 5.557

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V512_dim0_contiguousTrue_cpu
# Input: R: 256, V: 512, dim: 0, contiguous: True, device: cpu
Forward Execution Time (us) : 7.919

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V512_dim0_contiguousTrue_cuda
# Input: R: 256, V: 512, dim: 0, contiguous: True, device: cuda
Forward Execution Time (us) : 5.759

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V512_dim0_contiguousFalse_cpu
# Input: R: 256, V: 512, dim: 0, contiguous: False, device: cpu
Forward Execution Time (us) : 12.130

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V512_dim0_contiguousFalse_cuda
# Input: R: 256, V: 512, dim: 0, contiguous: False, device: cuda
Forward Execution Time (us) : 5.694

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V512_dim1_contiguousTrue_cpu
# Input: R: 256, V: 512, dim: 1, contiguous: True, device: cpu
Forward Execution Time (us) : 8.749

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V512_dim1_contiguousTrue_cuda
# Input: R: 256, V: 512, dim: 1, contiguous: True, device: cuda
Forward Execution Time (us) : 5.604

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V512_dim1_contiguousFalse_cpu
# Input: R: 256, V: 512, dim: 1, contiguous: False, device: cpu
Forward Execution Time (us) : 9.662

# Benchmarking PyTorch: sum
# Mode: Eager
# Name: sum_R256_V512_dim1_contiguousFalse_cuda
# Input: R: 256, V: 512, dim: 1, contiguous: False, device: cuda
Forward Execution Time (us) : 5.859

