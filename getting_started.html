<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>lamppp: Getting Started</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">lamppp
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="index.html">Lamp++ Documentation</a></li>  </ul>
</div>
</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title">Getting Started</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Let's get you up and running! This should take about 10 minutes if everything goes smoothly, or maybe 30 minutes if you hit some bumps along the way.</p>
<h2><a class="anchor" id="autotoc_md0"></a>
What you'll need</h2>
<p>Required:**</p><ul>
<li>CMake 3.24 or newer (check with <code>cmake --version</code>)</li>
<li>A C++20 compiler (GCC 11+, Clang 12+, or MSVC 2019+)</li>
<li><p class="startli">OpenMP (usually comes with your compiler)</p>
<p class="startli">Optional but recommended:**</p>
</li>
<li>CUDA toolkit (if you want GPU acceleration &ndash; HIGHLY RECOMMENDED!)</li>
<li><p class="startli">Python 3.11+ (for running tests and examples)</p>
<p class="startli">Quick compatibility check:** </p><div class="fragment"><div class="line">cmake --version  # Should be 3.24+</div>
<div class="line">g++ --version    # Should support C++20</div>
<div class="line">nvcc --version   # Optional, for CUDA support</div>
</div><!-- fragment --></li>
</ul>
<h2><a class="anchor" id="autotoc_md1"></a>
Building Lamp++</h2>
<h3><a class="anchor" id="autotoc_md2"></a>
The basic build</h3>
<div class="fragment"><div class="line">git clone https://github.com/clay-arras/lamp.git</div>
<div class="line">cd lamp</div>
<div class="line">cmake -S . -B build</div>
<div class="line">cmake --build build</div>
</div><!-- fragment --><p>That's it for a CPU-only build. Everything should compile in under a minute.</p>
<h3><a class="anchor" id="autotoc_md3"></a>
With CUDA support</h3>
<p>If you have a NVIDIA GPU and want to use it:</p>
<div class="fragment"><div class="line">cmake -S . -B build -DLMP_ENABLE_CUDA=ON</div>
<div class="line">cmake --build build</div>
</div><!-- fragment --><p>The build system will auto-detect your GPU architecture, so you don't need to worry about compute capabilities.</p>
<h3><a class="anchor" id="autotoc_md4"></a>
Build types and options</h3>
<p>Release build (fast, no debug info):** </p><div class="fragment"><div class="line">cmake -S . -B build -DCMAKE_BUILD_TYPE=Release -DLMP_ENABLE_CUDA=ON</div>
<div class="line">cmake --build build</div>
</div><!-- fragment --><p>Debug build (slower, with debug symbols):** </p><div class="fragment"><div class="line">cmake -S . -B build -DCMAKE_BUILD_TYPE=Debug -DLMP_ENABLE_CUDA=ON</div>
<div class="line">cmake --build build</div>
</div><!-- fragment --><p>With code coverage (for contributors):** </p><div class="fragment"><div class="line">cmake -S . -B build -DLMP_ENABLE_COVERAGE=ON</div>
<div class="line">cmake --build build</div>
</div><!-- fragment --><p>The Release build includes <code>-march=native</code> and <code>-ffast-math</code>, so it's optimized for your specific CPU. Debug builds include helpful debug symbols and assertions.</p>
<h2><a class="anchor" id="autotoc_md5"></a>
Your first program</h2>
<p>Create a file called <code>test.cpp</code>:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;lamppp/lamppp.hpp&quot;</span></div>
<div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">int</span> main() {</div>
<div class="line">    <span class="comment">// Create some data</span></div>
<div class="line">    std::vector&lt;float&gt; data_a = {1.0f, 2.0f, 3.0f, 4.0f};</div>
<div class="line">    std::vector&lt;float&gt; data_b = {2.0f, 3.0f, 4.0f, 5.0f};</div>
<div class="line">    </div>
<div class="line">    <span class="comment">// Make tensors (use CPU if you don&#39;t have CUDA)</span></div>
<div class="line">    <a class="code hl_class" href="classlmp_1_1tensor_1_1Tensor.html">lmp::Tensor</a> tensor_a(data_a, {2, 2}, lmp::DeviceType::CPU, lmp::DataType::Float32);</div>
<div class="line">    <a class="code hl_class" href="classlmp_1_1tensor_1_1Tensor.html">lmp::Tensor</a> tensor_b(data_b, {2, 2}, lmp::DeviceType::CPU, lmp::DataType::Float32);</div>
<div class="line">    </div>
<div class="line">    <span class="comment">// Wrap in Variables to track gradients</span></div>
<div class="line">    <a class="code hl_class" href="classlmp_1_1autograd_1_1Variable.html">lmp::Variable</a> a(tensor_a, <span class="keyword">true</span>);  <span class="comment">// requires_grad=true</span></div>
<div class="line">    <a class="code hl_class" href="classlmp_1_1autograd_1_1Variable.html">lmp::Variable</a> b(tensor_b, <span class="keyword">true</span>);</div>
<div class="line">    </div>
<div class="line">    <span class="comment">// Do some computation</span></div>
<div class="line">    <a class="code hl_class" href="classlmp_1_1autograd_1_1Variable.html">lmp::Variable</a> c = a * b;</div>
<div class="line">    <a class="code hl_class" href="classlmp_1_1autograd_1_1Variable.html">lmp::Variable</a> loss = lmp::sum(c);</div>
<div class="line">    </div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Forward pass result: &quot;</span> &lt;&lt; loss.data() &lt;&lt; std::endl;</div>
<div class="line">    </div>
<div class="line">    <span class="comment">// Compute gradients</span></div>
<div class="line">    loss.backward();</div>
<div class="line">    </div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Gradient of a:\n&quot;</span> &lt;&lt; a.grad() &lt;&lt; std::endl;</div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Gradient of b:\n&quot;</span> &lt;&lt; b.grad() &lt;&lt; std::endl;</div>
<div class="line">    </div>
<div class="line">    <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
<div class="ttc" id="aclasslmp_1_1autograd_1_1Variable_html"><div class="ttname"><a href="classlmp_1_1autograd_1_1Variable.html">lmp::autograd::Variable</a></div><div class="ttdef"><b>Definition</b> variable.hpp:37</div></div>
<div class="ttc" id="aclasslmp_1_1tensor_1_1Tensor_html"><div class="ttname"><a href="classlmp_1_1tensor_1_1Tensor.html">lmp::tensor::Tensor</a></div><div class="ttdoc">Main tensor object for Lamppp.</div><div class="ttdef"><b>Definition</b> tensor.hpp:29</div></div>
</div><!-- fragment --><p>To compile and run it: </p><div class="fragment"><div class="line">g++ -std=c++20 -I./include test.cpp -L./build/src/tensor -L./build/src/autograd -ltensor_core -lautograd_core -fopenmp -o test</div>
<div class="line">./test</div>
</div><!-- fragment --><p>Or if you built with CUDA: </p><div class="fragment"><div class="line">g++ -std=c++20 -I./include test.cpp -L./build/src/tensor -L./build/src/autograd -ltensor_core -lautograd_core -fopenmp -lcuda -lcudart -o test</div>
<div class="line">./test</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md6"></a>
Running the examples</h2>
<p>The MNIST example is a good way to see everything working together:</p>
<p>First, get the data:** </p><div class="fragment"><div class="line">cd examples</div>
<div class="line">mkdir -p ../data &amp;&amp; cd ../data</div>
<div class="line">curl -L -o mnist-in-csv.zip https://www.kaggle.com/api/v1/datasets/download/oddrationale/mnist-in-csv</div>
<div class="line">unzip mnist-in-csv.zip</div>
<div class="line">cd ..</div>
</div><!-- fragment --><p>Run the example:** </p><div class="fragment"><div class="line">./build/examples/mnist</div>
</div><!-- fragment --><p>This trains a simple 2-layer neural network on MNIST. You should see training accuracy improving over time. The network gets to about 85-90% accuracy, which isn't state-of-the-art but shows that everything is working.</p>
<h2><a class="anchor" id="autotoc_md7"></a>
Running tests</h2>
<p>Basic test suite:** </p><div class="fragment"><div class="line">cd build</div>
<div class="line">ctest</div>
</div><!-- fragment --><p>Individual test suites:** </p><div class="fragment"><div class="line">./tests/tensor_tests      # Test tensor operations</div>
<div class="line">./tests/autograd_tests    # Test gradient computation</div>
</div><!-- fragment --><p>With verbose output:** </p><div class="fragment"><div class="line">ctest --verbose</div>
</div><!-- fragment --><p>The tests cover all the basic tensor operations, gradient computation, and CUDA kernels (if enabled). They should all pass on a fresh build.</p>
<h2><a class="anchor" id="autotoc_md8"></a>
Running benchmarks</h2>
<div class="fragment"><div class="line">./build/benchmarks/reg_bench_short   # Quick benchmark</div>
<div class="line">./build/benchmarks/reg_bench_long    # Thorough benchmark</div>
</div><!-- fragment --><p>These will give you an idea of performance on your system. The benchmarks compare different operation implementations and should help identify any performance issues. You can also check the corresponding Pytorch benchmarks to see how the two libraries compare.</p>
<h2><a class="anchor" id="autotoc_md9"></a>
Common issues and solutions</h2>
<p>CUDA not found errors:**</p><ul>
<li>Make sure CUDA toolkit is installed and in your PATH</li>
<li>Try <code>nvcc --version</code> to verify installation</li>
<li><p class="startli">You can always build without CUDA using <code>-DLMP_ENABLE_CUDA=OFF</code></p>
<p class="startli">OpenMP linking errors:**</p>
</li>
<li>Install OpenMP development packages</li>
<li>On Ubuntu: <code>sudo apt install libomp-dev</code></li>
<li><p class="startli">On macOS: <code>brew install libomp</code></p>
<p class="startli">Tests failing:**</p>
</li>
<li>Make sure you're in the build directory when running ctest</li>
<li>Try a clean rebuild: <code>rm -rf build &amp;&amp; mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; make</code> </li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
